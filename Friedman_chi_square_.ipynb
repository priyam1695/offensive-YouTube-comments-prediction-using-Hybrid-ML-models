{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "4640f2bd-c229-42a0-b180-e266d6958029",
    "_uuid": "5a8550ea-097d-403c-91c1-3c3b5244d194"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/finaldata/YouTube_Dadvar_2014.csv\n",
      "../input/finaldata/glove.6B.100d.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn import svm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, Dense, Embedding, Dropout,MaxPooling1D, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # linear algebra\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras\n",
    "import keras.metrics\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report, f1_score\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "import tensorflow \n",
    "from tensorflow.python.lib.io import file_io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "dc2d0fab-c59a-4c93-ad61-d30b1b6a9929",
    "_uuid": "c16df588-b323-4902-bf21-d53eb3520920"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/finaldata/YouTube_Dadvar_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "dad535a7-3333-40e0-b027-4c77e5798f74",
    "_uuid": "9ae3ad68-a588-4a36-859d-049b6a0cda55"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserIndex</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Number of Comments</th>\n",
       "      <th>Number of Subscribers</th>\n",
       "      <th>Membership Duration</th>\n",
       "      <th>Number of Uploads</th>\n",
       "      <th>Profanity in UserID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>Unnamed: 30</th>\n",
       "      <th>Unnamed: 31</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>Unnamed: 33</th>\n",
       "      <th>Unnamed: 34</th>\n",
       "      <th>Unnamed: 35</th>\n",
       "      <th>Unnamed: 36</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>Does N.e.bodyelse Hear her Crazy ass Screamin ...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X2</td>\n",
       "      <td>There are so many things that are incorrect wi...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X3</td>\n",
       "      <td>3:26 hahah my boyfriend showed this song to me...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X2218</td>\n",
       "      <td>dick beyonce fuck y a ass hole you are truely ...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X5</td>\n",
       "      <td>DongHaeTaemin and Kai ;A; luhansehun and bacon...</td>\n",
       "      <td>11</td>\n",
       "      <td>173</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserIndex                                           Comments  \\\n",
       "0        X1  Does N.e.bodyelse Hear her Crazy ass Screamin ...   \n",
       "1        X2  There are so many things that are incorrect wi...   \n",
       "2        X3  3:26 hahah my boyfriend showed this song to me...   \n",
       "3     X2218  dick beyonce fuck y a ass hole you are truely ...   \n",
       "4        X5  DongHaeTaemin and Kai ;A; luhansehun and bacon...   \n",
       "\n",
       "   Number of Comments  Number of Subscribers  Membership Duration  \\\n",
       "0                  10                      1                    3   \n",
       "1                   3                      0                    6   \n",
       "2                   7                      0                    3   \n",
       "3                  34                      0                    3   \n",
       "4                  11                    173                    5   \n",
       "\n",
       "   Number of Uploads  Profanity in UserID  Age  Class  Unnamed: 9  ...  \\\n",
       "0                  3                    0   15      0         NaN  ...   \n",
       "1                  5                    0   31      0         NaN  ...   \n",
       "2                  5                    0   43      1         NaN  ...   \n",
       "3                  5                    0   44      1         NaN  ...   \n",
       "4                  5                    0   21      0         NaN  ...   \n",
       "\n",
       "   Unnamed: 28  Unnamed: 29  Unnamed: 30  Unnamed: 31  Unnamed: 32  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 33  Unnamed: 34  Unnamed: 35  Unnamed: 36  Unnamed: 37  \n",
       "0          NaN          NaN          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "079ed963-a712-436a-9848-1da1832d71b0",
    "_uuid": "52364acd-c989-469c-a39d-be61ba89a97a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3464, 38)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "8bc19bb0-5214-4089-ae08-aabd0438197d",
    "_uuid": "108950d8-dabe-49a6-8ae8-0842dcbf1f36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "c0b19271-ec99-4aa5-8d87-151c76580e85",
    "_uuid": "bd417589-8cd4-4f4d-a842-adbef00b01a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3464, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(data.columns[data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "564fb2c8-8c50-4845-8302-bf894ca6f2f4",
    "_uuid": "aebf4a5a-c219-4fc3-a298-c8ea7502669f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserIndex                object\n",
       "Comments                 object\n",
       "Number of Comments        int64\n",
       "Number of Subscribers     int64\n",
       "Membership Duration       int64\n",
       "Number of Uploads         int64\n",
       "Profanity in UserID       int64\n",
       "Age                       int64\n",
       "Class                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b9f26868-d446-4446-a469-e94ff8467f46",
    "_uuid": "f8a8e671-982b-48cf-84c4-68bbde4ef65e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserIndex                False\n",
       "Comments                 False\n",
       "Number of Comments       False\n",
       "Number of Subscribers    False\n",
       "Membership Duration      False\n",
       "Number of Uploads        False\n",
       "Profanity in UserID      False\n",
       "Age                      False\n",
       "Class                    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "6e4c6880-6dc9-4932-a2b1-18bc78d71633",
    "_uuid": "27390bdd-c240-4b42-bddf-2bf6f0505ef1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UserIndex', 'Comments', 'Number of Comments', 'Number of Subscribers',\n",
       "       'Membership Duration', 'Number of Uploads', 'Profanity in UserID',\n",
       "       'Age', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "d4482c90-38ba-424e-83ff-4905c4bcb153",
    "_uuid": "250d539f-1e99-4982-a2b5-19cf978ee541"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Comments</th>\n",
       "      <th>Number of Subscribers</th>\n",
       "      <th>Membership Duration</th>\n",
       "      <th>Number of Uploads</th>\n",
       "      <th>Profanity in UserID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3464.000000</td>\n",
       "      <td>3464.000000</td>\n",
       "      <td>3464.000000</td>\n",
       "      <td>3464.000000</td>\n",
       "      <td>3464.000000</td>\n",
       "      <td>3464.000000</td>\n",
       "      <td>3464.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.452367</td>\n",
       "      <td>304.318995</td>\n",
       "      <td>3.714781</td>\n",
       "      <td>10.288395</td>\n",
       "      <td>0.113164</td>\n",
       "      <td>24.879042</td>\n",
       "      <td>0.12067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.862517</td>\n",
       "      <td>15520.532319</td>\n",
       "      <td>1.392837</td>\n",
       "      <td>28.646525</td>\n",
       "      <td>0.316839</td>\n",
       "      <td>13.286361</td>\n",
       "      <td>0.32579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>912377.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>820.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Comments  Number of Subscribers  Membership Duration  \\\n",
       "count         3464.000000            3464.000000          3464.000000   \n",
       "mean            15.452367             304.318995             3.714781   \n",
       "std             10.862517           15520.532319             1.392837   \n",
       "min              1.000000               0.000000             2.000000   \n",
       "25%              6.000000               0.000000             3.000000   \n",
       "50%             14.000000               2.000000             3.000000   \n",
       "75%             23.000000               7.000000             4.000000   \n",
       "max             50.000000          912377.000000             9.000000   \n",
       "\n",
       "       Number of Uploads  Profanity in UserID          Age       Class  \n",
       "count        3464.000000          3464.000000  3464.000000  3464.00000  \n",
       "mean           10.288395             0.113164    24.879042     0.12067  \n",
       "std            28.646525             0.316839    13.286361     0.32579  \n",
       "min             1.000000             0.000000    13.000000     0.00000  \n",
       "25%             5.000000             0.000000    18.000000     0.00000  \n",
       "50%             5.000000             0.000000    21.000000     0.00000  \n",
       "75%             5.000000             0.000000    27.000000     0.00000  \n",
       "max           820.000000             1.000000   112.000000     1.00000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dupli = data.drop_duplicates()\n",
    "data=data_dupli\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "62ab1588-a2c1-46a2-9ddd-9a7418a4f28b",
    "_uuid": "da4e01ef-d29f-428b-ab2d-d12f7117a162"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "data['Class']=data['Class'].astype(str)\n",
    "le = LabelEncoder()\n",
    "data['Class'] = le.fit_transform(data['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "59dc5b12-6f3d-44b1-9439-082d4d0f7eaa",
    "_uuid": "774cdbdd-3701-4eaa-973e-a0e6fc95e9a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a26a9d4a8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAACkBJREFUeJzt3F+Ipfddx/HP190ktbZsEjdK2AQnkVAMVGpYSkHphUqaPxdR6EV6Y9BCoFrQCy9WClLvoqAXQrFEDFaRploVA63UoJXeaNqJ5s+GsGYSI90kdCmxa6Vgbfx5cX7TjtuZ2dl6zs75bl8vOMw5zzw8+/vuc/a95zxnZ2uMEQD6+J7DXgAAl0a4AZoRboBmhBugGeEGaEa4AZoRboBmhBugGeEGaOboKg56/PjxsbGxsYpDA1yRnnzyyS+PMW44yL4rCffGxkY2NzdXcWiAK1JV/dtB93WpBKAZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZoRrgBmhFugGaEG6AZ4QZo5ugqDvrsK+ezcepTqzj00r380L2HvQSAS+IVN0Azwg3QjHADNCPcAM0IN0Azwg3QjHADNCPcAM0IN0Azwg3QjHADNCPcAM0IN0Azwg3QjHADNCPcAM0IN0Azwg3QjHADNCPcAM0IN0Azwg3QzEXDXVWPVNW5qjp9ORYEwP4O8or7D5PcteJ1AHBAFw33GONzSV6/DGsB4ABc4wZoZmnhrqoHq2qzqjbf+Nr5ZR0WgAssLdxjjIfHGCfHGCePvPnYsg4LwAVcKgFo5iD/HPDjSf4hyduq6mxVvX/1ywJgL0cvtsMY432XYyEAHIxLJQDNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM0dXcdC3nziWzYfuXcWhAb7recUN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0IxwAzQj3ADNCDdAM8IN0MzRVRz02VfOZ+PUp1ZxaIC19PJD9162X8srboBmhBugGeEGaEa4AZoRboBmhBugGeEGaEa4AZoRboBmhBugGeEGaEa4AZoRboBmhBugGeEGaEa4AZoRboBmhBugGeEGaEa4AZoRboBmhBugGeEGaOZA4a6qu6rqTFVtVdWpVS8KgL1dNNxVdSTJR5LcneT2JO+rqttXvTAAdneQV9zvTLI1xnhpjPH1JI8muW+1ywJgLwcJ94kkX9zx+Ozc9n9U1YNVtVlVm2987fyy1gfABQ4S7tpl2/i2DWM8PMY4OcY4eeTNx/7/KwNgVwcJ99kkN+94fFOSV1ezHAAu5iDh/kKS26rqlqq6Osn9SR5b7bIA2MvRi+0wxvhGVX0wyWeSHEnyyBjjuZWvDIBdXTTcSTLG+HSST694LQAcgJ+cBGhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaObqKg779xLFsPnTvKg4N8F3PK26AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboBnhBmhGuAGaEW6AZoQboJkaYyz/oFVfTXJm6Qc+PMeTfPmwF7FEV9o8yZU3k3nW37Jn+qExxg0H2fHoEn/Rnc6MMU6u6NiXXVVtmme9XWkzmWf9HeZMLpUANCPcAM2sKtwPr+i4h8U86+9Km8k86+/QZlrJh5MArI5LJQDNLDXcVXVXVZ2pqq2qOrXMY69SVb1cVc9W1VNVtTm3XV9Vj1fVC/PrdXN7VdXvzhmfqao7Dnf1C1X1SFWdq6rTO7Zd8gxV9cDc/4WqeuAwZpnr2G2eD1fVK/M8PVVV9+z43q/Nec5U1Xt2bF+L52RV3VxVn62q56vquar65bm95TnaZ57O5+hNVfX5qnp6zvQbc/stVfXE/P3+RFVdPbdfMx9vze9v7DjWrrMuzRhjKbckR5K8mOTWJFcneTrJ7cs6/ipvSV5OcvyCbb+V5NS8fyrJb8779yT56ySV5F1Jnjjs9c91vTvJHUlOf6czJLk+yUvz63Xz/nVrNM+Hk/zqLvvePp9v1yS5ZT4Pj6zTczLJjUnumPffmuRf5rpbnqN95ul8jirJW+b9q5I8MX/v/zTJ/XP7R5N8YN7/xSQfnffvT/KJ/WZd5lqX+Yr7nUm2xhgvjTG+nuTRJPct8fiX231JPjbvfyzJz+zY/kdj4R+TXFtVNx7GAncaY3wuyesXbL7UGd6T5PExxutjjH9P8niSu1a/+m+3xzx7uS/Jo2OM/xpj/GuSrSyej2vznBxjvDbG+Kd5/6tJnk9yIk3P0T7z7KXDORpjjP+cD6+at5HkJ5N8cm6/8Bxtn7tPJvmpqqrsPevSLDPcJ5J8ccfjs9n/RK6TkeRvqurJqnpwbvvBMcZryeJJmuQH5vZOc17qDB1m++C8dPDI9mWFNJtnvqX+sSxe0bU/RxfMkzQ+R1V1pKqeSnIui78UX0zylTHGN3ZZ3zfXPr9/Psn35zLMtMxw1y7buvyTlR8fY9yR5O4kv1RV795n385zbttrhnWf7feS/HCSdyR5Lclvz+1t5qmqtyT58yS/Msb4j/123WXb2s20yzytz9EY440xxjuS3JTFq+Qf2W23+fXQZlpmuM8muXnH45uSvLrE46/MGOPV+fVckr/M4oR9afsSyPx6bu7eac5LnWGtZxtjfGn+wfqfJL+fb739bDFPVV2VReT+ZIzxF3Nz23O02zzdz9G2McZXkvx9Fte4r62q7f8eZOf6vrn2+f1jWVzeW/lMywz3F5LcNj+BvTqLi/WPLfH4K1FV31dVb92+n+TOJKezWPv2J/YPJPmref+xJD83P/V/V5Lz229119ClzvCZJHdW1XXzLe6dc9tauOCzhJ/N4jwli3nun5/y35LktiSfzxo9J+e1zz9I8vwY43d2fKvlOdprnubn6Iaqunbe/94kP53FtfvPJnnv3O3Cc7R97t6b5O/G4tPJvWZdniV/KntPFp8uv5jkQ8s89qpuWXya/fS8Pbe97iyuVf1tkhfm1+vHtz55/sic8dkkJw97hrmuj2fx1vS/s/gb//3fyQxJfiGLD1O2kvz8ms3zx3O9z2Txh+PGHft/aM5zJsnd6/acTPITWbxdfibJU/N2T9dztM88nc/Rjyb557n200l+fW6/NYvwbiX5syTXzO1vmo+35vdvvdisy7r5yUmAZvzkJEAzwg3QjHADNCPcAM0IN0Azwg3QjHADNCPcAM38L4WN3PpDy80BAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Class'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "f9e56d1e-1adf-4efb-be79-585a8357f4ca",
    "_uuid": "571a4234-46f5-455b-9735-08ff1dfc087b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do nebodyels hear crazi as screamin hoe every...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there mani thing incorrect comment unbeliev g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hahah boyfriend show song me tooo be seizur o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dick beyonc fuck as hole trueli dog bitch pha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>donghaetaemin kai a luhansehun bacon xd taemi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Comments  Class\n",
       "0   do nebodyels hear crazi as screamin hoe every...      0\n",
       "1   there mani thing incorrect comment unbeliev g...      0\n",
       "2   hahah boyfriend show song me tooo be seizur o...      1\n",
       "3   dick beyonc fuck as hole trueli dog bitch pha...      1\n",
       "4   donghaetaemin kai a luhansehun bacon xd taemi...      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kernelprocess\n",
    "\n",
    "df = kernelprocess.processing(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "file = shuffle(df, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame(file['Class'])\n",
    "X = pd.DataFrame(file['Comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv = KFold(n_splits= 10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,2)).fit_transform(X['Comments'].values)\n",
    "y=Y['Class'].values\n",
    "\n",
    "def Baseline(y, cv, tfidf):\n",
    "    #SVM with tf-idf\n",
    "    for train, test in cv.split(tfidf):  \n",
    "        \n",
    "        Xtrain, Xtest = tfidf[train], tfidf[test]\n",
    "        Ytrain, Ytest = y[train], y[test]\n",
    "        from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "        rus = RandomUnderSampler()\n",
    "        x_rus, y_rus = rus.fit_sample(Xtrain, Ytrain)\n",
    "        \n",
    "        SVM = svm.SVC(C=1.0, kernel='linear')\n",
    "        SVM.fit(x_rus, y_rus)\n",
    "        \n",
    "        predict_SVM = SVM.predict(Xtest)\n",
    "    \n",
    "    return (x_rus, y_rus,Ytest, SVM, predict_SVM)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  [0.68421053 0.52631579 0.42105263 0.48648649 0.56756757 0.48648649\n",
      " 0.75675676 0.54054054 0.43243243 0.56756757]\n"
     ]
    }
   ],
   "source": [
    "x_rus, y_rus,Ytest, SVM, predict_SVM = Baseline(y, cv,tfidf)\n",
    "scoreSVM = cross_val_score(SVM, x_rus, y_rus, cv=10, scoring='recall')\n",
    "print(\"SVM Accuracy Score -> \", scoreSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history):\n",
    "        fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "        # summarize history for accuracy\n",
    "        axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "        axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "        axs[0].set_title('Model Accuracy')\n",
    "        axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "        axs[0].legend(['train', 'test'], loc='best')\n",
    "        # summarize history for loss\n",
    "        axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "        axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "        axs[1].set_title('Model Loss')\n",
    "        axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "        axs[1].legend(['train', 'test'], loc='best')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None, split=' ',lower=False)\n",
    "tokenizer.fit_on_texts(X['Comments'].values)\n",
    "x = tokenizer.texts_to_sequences(X['Comments'].values)\n",
    "wordindex = tokenizer.word_index\n",
    "vocab_size = len(wordindex) + 1\n",
    "token = pad_sequences(x, padding  = 'post', maxlen = 3000) #max comment length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 400000 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3249: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\n",
    "# load whole embedding into memory\n",
    "print('Indexing word vectors.')\n",
    "    \n",
    "embeddings_index = {}\n",
    "f = file_io.FileIO('../input/finaldata/glove.6B.100d.txt', mode='r')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "    \n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "#emb_dim could be a parameter\n",
    "    \n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean = all_embs.mean() \n",
    "emb_std = all_embs.std() \n",
    "emb_mean,emb_std\n",
    "emb_dim=100\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (vocab_size, emb_dim ))\n",
    "for word, i in wordindex.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5480 samples, validate on 347 samples\n",
      "Epoch 1/4\n",
      "5480/5480 [==============================] - 3s 589us/step - loss: 4.8544 - recall: 0.4962 - val_loss: 3.7419 - val_recall: 0.9538\n",
      "Epoch 2/4\n",
      "5480/5480 [==============================] - 1s 215us/step - loss: 2.7976 - recall: 0.6839 - val_loss: 2.0902 - val_recall: 0.2272\n",
      "Epoch 3/4\n",
      "5480/5480 [==============================] - 1s 216us/step - loss: 1.6726 - recall: 0.7756 - val_loss: 1.3513 - val_recall: 0.3452\n",
      "Epoch 4/4\n",
      "5480/5480 [==============================] - 1s 217us/step - loss: 1.0843 - recall: 0.7804 - val_loss: 0.9158 - val_recall: 0.1920\n",
      "Train on 5506 samples, validate on 347 samples\n",
      "Epoch 1/4\n",
      "5506/5506 [==============================] - 2s 388us/step - loss: 4.8128 - recall: 0.4907 - val_loss: 3.6856 - val_recall: 0.9060\n",
      "Epoch 2/4\n",
      "5506/5506 [==============================] - 1s 216us/step - loss: 2.7605 - recall: 0.6883 - val_loss: 2.0784 - val_recall: 0.2631\n",
      "Epoch 3/4\n",
      "5506/5506 [==============================] - 1s 216us/step - loss: 1.6505 - recall: 0.7421 - val_loss: 1.3408 - val_recall: 0.3583\n",
      "Epoch 4/4\n",
      "5506/5506 [==============================] - 1s 215us/step - loss: 1.0716 - recall: 0.7620 - val_loss: 0.9330 - val_recall: 0.2504\n",
      "Train on 5474 samples, validate on 347 samples\n",
      "Epoch 1/4\n",
      "5474/5474 [==============================] - 2s 371us/step - loss: 4.8284 - recall: 0.4777 - val_loss: 3.6982 - val_recall: 0.9510\n",
      "Epoch 2/4\n",
      "5474/5474 [==============================] - 1s 215us/step - loss: 2.7827 - recall: 0.6869 - val_loss: 2.1180 - val_recall: 0.4470\n",
      "Epoch 3/4\n",
      "5474/5474 [==============================] - 1s 215us/step - loss: 1.6737 - recall: 0.7541 - val_loss: 1.3527 - val_recall: 0.3104\n",
      "Epoch 4/4\n",
      "5474/5474 [==============================] - 1s 217us/step - loss: 1.0905 - recall: 0.7737 - val_loss: 1.0473 - val_recall: 0.5174\n",
      "Train on 5484 samples, validate on 347 samples\n",
      "Epoch 1/4\n",
      "5484/5484 [==============================] - 2s 388us/step - loss: 4.8191 - recall: 0.5028 - val_loss: 3.6817 - val_recall: 0.9824\n",
      "Epoch 2/4\n",
      "5484/5484 [==============================] - 1s 217us/step - loss: 2.7674 - recall: 0.6708 - val_loss: 2.1207 - val_recall: 0.3550\n",
      "Epoch 3/4\n",
      "5484/5484 [==============================] - 1s 218us/step - loss: 1.6593 - recall: 0.7608 - val_loss: 1.3294 - val_recall: 0.2733\n",
      "Epoch 4/4\n",
      "5484/5484 [==============================] - 1s 217us/step - loss: 1.0791 - recall: 0.7753 - val_loss: 0.8996 - val_recall: 0.1730\n",
      "Train on 5476 samples, validate on 346 samples\n",
      "Epoch 1/4\n",
      "5476/5476 [==============================] - 2s 392us/step - loss: 4.8270 - recall: 0.4650 - val_loss: 3.6747 - val_recall: 0.9512\n",
      "Epoch 2/4\n",
      "5476/5476 [==============================] - 1s 218us/step - loss: 2.7860 - recall: 0.6881 - val_loss: 2.1052 - val_recall: 0.2677\n",
      "Epoch 3/4\n",
      "5476/5476 [==============================] - 1s 218us/step - loss: 1.6724 - recall: 0.7428 - val_loss: 1.3901 - val_recall: 0.5540\n",
      "Epoch 4/4\n",
      "5476/5476 [==============================] - 1s 217us/step - loss: 1.0849 - recall: 0.8009 - val_loss: 0.9269 - val_recall: 0.1264\n",
      "Train on 5492 samples, validate on 346 samples\n",
      "Epoch 1/4\n",
      "5492/5492 [==============================] - 2s 398us/step - loss: 4.8336 - recall: 0.4884 - val_loss: 3.6631 - val_recall: 0.8908\n",
      "Epoch 2/4\n",
      "5492/5492 [==============================] - 1s 215us/step - loss: 2.7860 - recall: 0.6840 - val_loss: 2.1497 - val_recall: 0.4866\n",
      "Epoch 3/4\n",
      "5492/5492 [==============================] - 1s 217us/step - loss: 1.6734 - recall: 0.7739 - val_loss: 1.3410 - val_recall: 0.3072\n",
      "Epoch 4/4\n",
      "5492/5492 [==============================] - 1s 216us/step - loss: 1.0863 - recall: 0.7755 - val_loss: 0.9278 - val_recall: 0.2192\n",
      "Train on 5474 samples, validate on 346 samples\n",
      "Epoch 1/4\n",
      "5474/5474 [==============================] - 2s 389us/step - loss: 4.8261 - recall: 0.4814 - val_loss: 3.7292 - val_recall: 0.9538\n",
      "Epoch 2/4\n",
      "5474/5474 [==============================] - 1s 218us/step - loss: 2.7774 - recall: 0.6852 - val_loss: 2.1063 - val_recall: 0.3940\n",
      "Epoch 3/4\n",
      "5474/5474 [==============================] - 1s 217us/step - loss: 1.6662 - recall: 0.7512 - val_loss: 1.3042 - val_recall: 0.1831\n",
      "Epoch 4/4\n",
      "5474/5474 [==============================] - 1s 218us/step - loss: 1.0829 - recall: 0.7857 - val_loss: 1.0310 - val_recall: 0.5315\n",
      "Train on 5470 samples, validate on 346 samples\n",
      "Epoch 1/4\n",
      "5470/5470 [==============================] - 2s 405us/step - loss: 4.8139 - recall: 0.4885 - val_loss: 3.7014 - val_recall: 0.8145\n",
      "Epoch 2/4\n",
      "5470/5470 [==============================] - 1s 217us/step - loss: 2.7704 - recall: 0.6965 - val_loss: 2.0682 - val_recall: 0.1845\n",
      "Epoch 3/4\n",
      "5470/5470 [==============================] - 1s 218us/step - loss: 1.6612 - recall: 0.7719 - val_loss: 1.3516 - val_recall: 0.3271\n",
      "Epoch 4/4\n",
      "5470/5470 [==============================] - 1s 218us/step - loss: 1.0779 - recall: 0.7911 - val_loss: 0.9517 - val_recall: 0.2582\n",
      "Train on 5482 samples, validate on 346 samples\n",
      "Epoch 1/4\n",
      "5482/5482 [==============================] - 2s 437us/step - loss: 4.8358 - recall: 0.4730 - val_loss: 3.7185 - val_recall: 0.9293\n",
      "Epoch 2/4\n",
      "5482/5482 [==============================] - 1s 217us/step - loss: 2.7849 - recall: 0.6968 - val_loss: 2.1235 - val_recall: 0.3948\n",
      "Epoch 3/4\n",
      "5482/5482 [==============================] - 1s 217us/step - loss: 1.6702 - recall: 0.7691 - val_loss: 1.3351 - val_recall: 0.3476\n",
      "Epoch 4/4\n",
      "5482/5482 [==============================] - 1s 217us/step - loss: 1.0837 - recall: 0.7898 - val_loss: 0.9306 - val_recall: 0.2079\n",
      "Train on 5490 samples, validate on 346 samples\n",
      "Epoch 1/4\n",
      "5490/5490 [==============================] - 2s 451us/step - loss: 4.8289 - recall: 0.4788 - val_loss: 3.7108 - val_recall: 0.8697\n",
      "Epoch 2/4\n",
      "5490/5490 [==============================] - 1s 218us/step - loss: 2.7889 - recall: 0.6919 - val_loss: 2.1341 - val_recall: 0.4919\n",
      "Epoch 3/4\n",
      "5490/5490 [==============================] - 1s 220us/step - loss: 1.6759 - recall: 0.7703 - val_loss: 1.3026 - val_recall: 0.0795\n",
      "Epoch 4/4\n",
      "5490/5490 [==============================] - 1s 217us/step - loss: 1.0906 - recall: 0.7700 - val_loss: 0.9526 - val_recall: 0.1861\n",
      "CNN Accuracy Score ->  [0.18770413435673508, 0.2303554325522882, 0.42003568379954576, 0.1567723373171232, 0.152601156620621, 0.20926232282825977, 0.5919075039769873, 0.23516377961704496, 0.19730250683823072, 0.1890723939575901]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "cvscorescnn = []\n",
    "for train, test in cv.split(token):  \n",
    "    #print(\"TRAIN:\", train, \"Test:\", test)\n",
    "    Xtrain, Xtest = token[train], token[test]\n",
    "    Ytrain, Ytest = y[train], y[test]\n",
    "    #smote\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X_train_res, y_train_res = sm.fit_sample(Xtrain, Ytrain)    \n",
    "    \n",
    "    seed = 120\n",
    "    np.random.seed(seed)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, weights = [embedding_matrix], trainable=False, input_length = X_train_res.shape[1]))\n",
    "    model.add(Conv1D(92, 5, activation='tanh'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(10, activation='tanh', kernel_regularizer = regularizers.l2(0.3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',loss= 'binary_crossentropy',metrics=([recall]))#sentropy',loss= imbalancedloss\n",
    "    \n",
    "    batch_size = 110\n",
    "    epochs = 4\n",
    "    model_history = model.fit(X_train_res,y_train_res, validation_data=(Xtest, Ytest),epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "    y_pred = model.predict_classes(Xtest)\n",
    "    score = model.evaluate(Xtest, Ytest, verbose=0)\n",
    "    cvscorescnn.append(score[1])\n",
    "print(\"CNN Accuracy Score -> \", cvscorescnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5480 samples, validate on 347 samples\n",
      "Epoch 1/10\n",
      "5480/5480 [==============================] - 29s 5ms/step - loss: 1.4703 - recall: 0.5444 - val_loss: 1.4294 - val_recall: 0.9274\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_recall,loss,recall\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5480/5480 [==============================] - 26s 5ms/step - loss: 1.0875 - recall: 0.6008 - val_loss: 1.0724 - val_recall: 0.8331\n",
      "Epoch 3/10\n",
      "5480/5480 [==============================] - 26s 5ms/step - loss: 0.8795 - recall: 0.5878 - val_loss: 0.8266 - val_recall: 0.6398\n",
      "Epoch 4/10\n",
      "5480/5480 [==============================] - 26s 5ms/step - loss: 0.7574 - recall: 0.5688 - val_loss: 0.7599 - val_recall: 0.2206\n",
      "Epoch 5/10\n",
      "5480/5480 [==============================] - 26s 5ms/step - loss: 0.6469 - recall: 0.5538 - val_loss: 0.6330 - val_recall: 0.0515\n",
      "Epoch 6/10\n",
      "5480/5480 [==============================] - 26s 5ms/step - loss: 0.5618 - recall: 0.6374 - val_loss: 0.6042 - val_recall: 0.0977\n",
      "Epoch 7/10\n",
      "5480/5480 [==============================] - 26s 5ms/step - loss: 0.4873 - recall: 0.7054 - val_loss: 0.5996 - val_recall: 0.2338\n",
      "Epoch 8/10\n",
      "5480/5480 [==============================] - 27s 5ms/step - loss: 0.4282 - recall: 0.7424 - val_loss: 0.5684 - val_recall: 0.0634\n",
      "Epoch 9/10\n",
      "5480/5480 [==============================] - 27s 5ms/step - loss: 0.4424 - recall: 0.7421 - val_loss: 0.6230 - val_recall: 0.1942\n",
      "Epoch 10/10\n",
      "5480/5480 [==============================] - 26s 5ms/step - loss: 0.3635 - recall: 0.7945 - val_loss: 0.5247 - val_recall: 0.0898\n",
      "Train on 5506 samples, validate on 347 samples\n",
      "Epoch 1/10\n",
      "5506/5506 [==============================] - 29s 5ms/step - loss: 1.4809 - recall: 0.5468 - val_loss: 1.3604 - val_recall: 0.8410\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_recall,loss,recall\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5506/5506 [==============================] - 27s 5ms/step - loss: 1.0921 - recall: 0.5902 - val_loss: 0.9947 - val_recall: 0.5334\n",
      "Epoch 3/10\n",
      "5506/5506 [==============================] - 27s 5ms/step - loss: 0.8777 - recall: 0.5666 - val_loss: 0.8645 - val_recall: 0.5285\n",
      "Epoch 4/10\n",
      "5506/5506 [==============================] - 27s 5ms/step - loss: 0.6910 - recall: 0.6172 - val_loss: 0.6871 - val_recall: 0.0507\n",
      "Epoch 5/10\n",
      "5506/5506 [==============================] - 27s 5ms/step - loss: 0.5619 - recall: 0.6641 - val_loss: 0.7822 - val_recall: 0.4184\n",
      "Epoch 6/10\n",
      "5506/5506 [==============================] - 27s 5ms/step - loss: 0.4976 - recall: 0.7237 - val_loss: 0.6651 - val_recall: 0.1766\n",
      "Epoch 7/10\n",
      "5506/5506 [==============================] - 27s 5ms/step - loss: 0.4654 - recall: 0.7315 - val_loss: 0.5942 - val_recall: 0.0903\n",
      "Epoch 8/10\n",
      "5506/5506 [==============================] - 27s 5ms/step - loss: 0.6859 - recall: 0.8347 - val_loss: 0.9060 - val_recall: 1.0000\n",
      "Epoch 9/10\n",
      "5506/5506 [==============================] - 27s 5ms/step - loss: 0.6716 - recall: 0.6119 - val_loss: 0.6665 - val_recall: 0.4966\n",
      "Epoch 10/10\n",
      "5506/5506 [==============================] - 27s 5ms/step - loss: 0.5491 - recall: 0.7582 - val_loss: 0.6271 - val_recall: 0.1983\n",
      "Train on 5474 samples, validate on 347 samples\n",
      "Epoch 1/10\n",
      "5474/5474 [==============================] - 29s 5ms/step - loss: 1.4709 - recall: 0.5811 - val_loss: 1.3651 - val_recall: 0.7670\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_recall,loss,recall\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5474/5474 [==============================] - 26s 5ms/step - loss: 1.0873 - recall: 0.6168 - val_loss: 1.0543 - val_recall: 0.6907\n",
      "Epoch 3/10\n",
      "5474/5474 [==============================] - 26s 5ms/step - loss: 0.8598 - recall: 0.5815 - val_loss: 0.8160 - val_recall: 0.2790\n",
      "Epoch 4/10\n",
      "5474/5474 [==============================] - 26s 5ms/step - loss: 0.6800 - recall: 0.6188 - val_loss: 0.7206 - val_recall: 0.2294\n",
      "Epoch 5/10\n",
      "5474/5474 [==============================] - 26s 5ms/step - loss: 0.5593 - recall: 0.6932 - val_loss: 0.7705 - val_recall: 0.4688\n",
      "Epoch 6/10\n",
      "5474/5474 [==============================] - 26s 5ms/step - loss: 0.5227 - recall: 0.7041 - val_loss: 0.6782 - val_recall: 0.3323\n",
      "Epoch 7/10\n",
      "5474/5474 [==============================] - 26s 5ms/step - loss: 0.4442 - recall: 0.7308 - val_loss: 0.5637 - val_recall: 0.1345\n",
      "Epoch 8/10\n",
      "5474/5474 [==============================] - 26s 5ms/step - loss: 0.4267 - recall: 0.7503 - val_loss: 0.5292 - val_recall: 0.1718\n",
      "Epoch 9/10\n",
      "5474/5474 [==============================] - 27s 5ms/step - loss: 0.4014 - recall: 0.7633 - val_loss: 0.6868 - val_recall: 0.2731\n",
      "Epoch 10/10\n",
      "5474/5474 [==============================] - 27s 5ms/step - loss: 0.3723 - recall: 0.7930 - val_loss: 0.6557 - val_recall: 0.3573\n",
      "Train on 5484 samples, validate on 347 samples\n",
      "Epoch 1/10\n",
      "5484/5484 [==============================] - 30s 6ms/step - loss: 1.4705 - recall: 0.5730 - val_loss: 1.3430 - val_recall: 0.8877\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_recall,loss,recall\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5484/5484 [==============================] - 26s 5ms/step - loss: 1.0862 - recall: 0.5930 - val_loss: 1.0766 - val_recall: 0.6946\n",
      "Epoch 3/10\n",
      "5484/5484 [==============================] - 26s 5ms/step - loss: 0.8748 - recall: 0.5748 - val_loss: 0.8973 - val_recall: 0.5381\n",
      "Epoch 4/10\n",
      "5484/5484 [==============================] - 26s 5ms/step - loss: 0.7324 - recall: 0.6089 - val_loss: 0.6526 - val_recall: 0.0748\n",
      "Epoch 5/10\n",
      "5484/5484 [==============================] - 26s 5ms/step - loss: 0.5694 - recall: 0.6635 - val_loss: 0.7669 - val_recall: 0.3918\n",
      "Epoch 6/10\n",
      "5484/5484 [==============================] - 26s 5ms/step - loss: 0.5194 - recall: 0.7079 - val_loss: 0.6259 - val_recall: 0.3572\n",
      "Epoch 7/10\n",
      "5484/5484 [==============================] - 26s 5ms/step - loss: 0.5474 - recall: 0.6540 - val_loss: 0.5914 - val_recall: 0.1673\n",
      "Epoch 8/10\n",
      "5484/5484 [==============================] - 27s 5ms/step - loss: 0.4650 - recall: 0.7061 - val_loss: 0.5936 - val_recall: 0.2324\n",
      "Epoch 9/10\n",
      "5484/5484 [==============================] - 26s 5ms/step - loss: 0.4308 - recall: 0.7335 - val_loss: 0.5287 - val_recall: 0.0947\n",
      "Epoch 10/10\n",
      "5484/5484 [==============================] - 26s 5ms/step - loss: 0.4232 - recall: 0.7473 - val_loss: 0.5214 - val_recall: 0.1145\n",
      "Train on 5476 samples, validate on 346 samples\n",
      "Epoch 1/10\n",
      "5476/5476 [==============================] - 31s 6ms/step - loss: 1.4738 - recall: 0.5768 - val_loss: 1.3043 - val_recall: 0.7497\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_recall,loss,recall\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5476/5476 [==============================] - 26s 5ms/step - loss: 1.0940 - recall: 0.5864 - val_loss: 1.0468 - val_recall: 0.6901\n",
      "Epoch 3/10\n",
      "5476/5476 [==============================] - 26s 5ms/step - loss: 0.8590 - recall: 0.5539 - val_loss: 0.9413 - val_recall: 0.7233\n",
      "Epoch 4/10\n",
      "5476/5476 [==============================] - 26s 5ms/step - loss: 0.6929 - recall: 0.6048 - val_loss: 0.6652 - val_recall: 0.1373\n",
      "Epoch 5/10\n",
      "5476/5476 [==============================] - 26s 5ms/step - loss: 0.5666 - recall: 0.6704 - val_loss: 0.6312 - val_recall: 0.2304\n",
      "Epoch 6/10\n",
      "5476/5476 [==============================] - 26s 5ms/step - loss: 0.5172 - recall: 0.6910 - val_loss: 0.6203 - val_recall: 0.2503\n",
      "Epoch 7/10\n",
      "5476/5476 [==============================] - 26s 5ms/step - loss: 0.4588 - recall: 0.7289 - val_loss: 0.5712 - val_recall: 0.2015\n",
      "Epoch 8/10\n",
      "5476/5476 [==============================] - 26s 5ms/step - loss: 0.4183 - recall: 0.7505 - val_loss: 0.7703 - val_recall: 0.4249\n",
      "Epoch 9/10\n",
      "5476/5476 [==============================] - 26s 5ms/step - loss: 0.3806 - recall: 0.7838 - val_loss: 0.5612 - val_recall: 0.1373\n",
      "Epoch 10/10\n",
      "5476/5476 [==============================] - 26s 5ms/step - loss: 0.5612 - recall: 0.7817 - val_loss: 0.5741 - val_recall: 0.1816\n",
      "Train on 5492 samples, validate on 346 samples\n",
      "Epoch 1/10\n",
      "5492/5492 [==============================] - 31s 6ms/step - loss: 1.4769 - recall: 0.5633 - val_loss: 1.3673 - val_recall: 0.9120\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_recall,loss,recall\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5492/5492 [==============================] - 28s 5ms/step - loss: 1.0947 - recall: 0.5935 - val_loss: 1.0408 - val_recall: 0.8264\n",
      "Epoch 3/10\n",
      "5492/5492 [==============================] - 27s 5ms/step - loss: 0.8828 - recall: 0.5416 - val_loss: 0.8939 - val_recall: 0.7596\n",
      "Epoch 4/10\n",
      "5492/5492 [==============================] - 27s 5ms/step - loss: 0.7528 - recall: 0.5686 - val_loss: 0.7044 - val_recall: 0.2795\n",
      "Epoch 5/10\n",
      "5492/5492 [==============================] - 27s 5ms/step - loss: 0.5907 - recall: 0.6796 - val_loss: 0.5498 - val_recall: 0.2127\n",
      "Epoch 6/10\n",
      "5492/5492 [==============================] - 26s 5ms/step - loss: 0.5195 - recall: 0.6976 - val_loss: 0.7494 - val_recall: 0.3830\n",
      "Epoch 7/10\n",
      "5492/5492 [==============================] - 27s 5ms/step - loss: 0.4558 - recall: 0.7506 - val_loss: 0.5355 - val_recall: 0.0848\n",
      "Epoch 8/10\n",
      "5492/5492 [==============================] - 27s 5ms/step - loss: 0.3991 - recall: 0.7838 - val_loss: 0.5007 - val_recall: 0.1092\n",
      "Epoch 9/10\n",
      "5492/5492 [==============================] - 27s 5ms/step - loss: 0.3604 - recall: 0.7897 - val_loss: 0.7310 - val_recall: 0.3888\n",
      "Epoch 10/10\n",
      "5492/5492 [==============================] - 27s 5ms/step - loss: 0.3082 - recall: 0.8403 - val_loss: 0.5177 - val_recall: 0.2005\n",
      "Train on 5474 samples, validate on 346 samples\n",
      "Epoch 1/10\n",
      "5474/5474 [==============================] - 31s 6ms/step - loss: 1.4672 - recall: 0.5847 - val_loss: 1.3540 - val_recall: 0.7956\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_recall,loss,recall\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5474/5474 [==============================] - 27s 5ms/step - loss: 1.0861 - recall: 0.5829 - val_loss: 0.9806 - val_recall: 0.7038\n",
      "Epoch 3/10\n",
      "5474/5474 [==============================] - 28s 5ms/step - loss: 0.8672 - recall: 0.5747 - val_loss: 0.8194 - val_recall: 0.2527\n",
      "Epoch 4/10\n",
      "5474/5474 [==============================] - 27s 5ms/step - loss: 0.7019 - recall: 0.5856 - val_loss: 0.8853 - val_recall: 0.4712\n",
      "Epoch 5/10\n",
      "5474/5474 [==============================] - 27s 5ms/step - loss: 0.5779 - recall: 0.6562 - val_loss: 0.6247 - val_recall: 0.0668\n",
      "Epoch 6/10\n",
      "5474/5474 [==============================] - 27s 5ms/step - loss: 0.5012 - recall: 0.7044 - val_loss: 0.5726 - val_recall: 0.0668\n",
      "Epoch 7/10\n",
      "5474/5474 [==============================] - 26s 5ms/step - loss: 0.4470 - recall: 0.7205 - val_loss: 0.6145 - val_recall: 0.2565\n",
      "Epoch 8/10\n",
      "5474/5474 [==============================] - 26s 5ms/step - loss: 0.4109 - recall: 0.7471 - val_loss: 0.5468 - val_recall: 0.1158\n",
      "Epoch 9/10\n",
      "5474/5474 [==============================] - 26s 5ms/step - loss: 0.3859 - recall: 0.7768 - val_loss: 0.5977 - val_recall: 0.2853\n",
      "Epoch 10/10\n",
      "5474/5474 [==============================] - 27s 5ms/step - loss: 0.3315 - recall: 0.8099 - val_loss: 0.5178 - val_recall: 0.1647\n",
      "Train on 5470 samples, validate on 346 samples\n",
      "Epoch 1/10\n",
      "5470/5470 [==============================] - 31s 6ms/step - loss: 1.4609 - recall: 0.5902 - val_loss: 1.3064 - val_recall: 0.5867\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_recall,loss,recall\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5470/5470 [==============================] - 26s 5ms/step - loss: 1.0770 - recall: 0.6091 - val_loss: 0.9886 - val_recall: 0.3748\n",
      "Epoch 3/10\n",
      "5470/5470 [==============================] - 26s 5ms/step - loss: 0.8526 - recall: 0.5894 - val_loss: 0.9344 - val_recall: 0.5231\n",
      "Epoch 4/10\n",
      "5470/5470 [==============================] - 27s 5ms/step - loss: 0.6629 - recall: 0.6472 - val_loss: 0.6840 - val_recall: 0.2428\n",
      "Epoch 5/10\n",
      "5470/5470 [==============================] - 27s 5ms/step - loss: 0.6116 - recall: 0.6350 - val_loss: 0.7908 - val_recall: 0.2750\n",
      "Epoch 6/10\n",
      "5470/5470 [==============================] - 26s 5ms/step - loss: 0.5177 - recall: 0.6860 - val_loss: 0.7178 - val_recall: 0.2013\n",
      "Epoch 7/10\n",
      "5470/5470 [==============================] - 26s 5ms/step - loss: 0.4770 - recall: 0.7153 - val_loss: 0.5180 - val_recall: 0.0318\n",
      "Epoch 8/10\n",
      "5470/5470 [==============================] - 26s 5ms/step - loss: 0.4383 - recall: 0.7419 - val_loss: 0.6728 - val_recall: 0.1002\n",
      "Epoch 9/10\n",
      "5470/5470 [==============================] - 26s 5ms/step - loss: 0.4050 - recall: 0.7647 - val_loss: 0.5167 - val_recall: 0.0318\n",
      "Epoch 10/10\n",
      "5470/5470 [==============================] - 26s 5ms/step - loss: 0.3693 - recall: 0.7903 - val_loss: 0.5393 - val_recall: 0.0472\n",
      "Train on 5482 samples, validate on 346 samples\n",
      "Epoch 1/10\n",
      "5482/5482 [==============================] - 32s 6ms/step - loss: 1.4648 - recall: 0.5428 - val_loss: 1.3750 - val_recall: 0.8367\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_recall,loss,recall\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5482/5482 [==============================] - 27s 5ms/step - loss: 1.0844 - recall: 0.5598 - val_loss: 1.0452 - val_recall: 0.7197\n",
      "Epoch 3/10\n",
      "5482/5482 [==============================] - 27s 5ms/step - loss: 0.8580 - recall: 0.5564 - val_loss: 0.7870 - val_recall: 0.1432\n",
      "Epoch 4/10\n",
      "5482/5482 [==============================] - 27s 5ms/step - loss: 0.6777 - recall: 0.6181 - val_loss: 0.6867 - val_recall: 0.1852\n",
      "Epoch 5/10\n",
      "5482/5482 [==============================] - 28s 5ms/step - loss: 0.5619 - recall: 0.6923 - val_loss: 0.6519 - val_recall: 0.2114\n",
      "Epoch 6/10\n",
      "5482/5482 [==============================] - 27s 5ms/step - loss: 0.4829 - recall: 0.7213 - val_loss: 0.7708 - val_recall: 0.3494\n",
      "Epoch 7/10\n",
      "5482/5482 [==============================] - 27s 5ms/step - loss: 0.4617 - recall: 0.7387 - val_loss: 0.6065 - val_recall: 0.1852\n",
      "Epoch 8/10\n",
      "5482/5482 [==============================] - 27s 5ms/step - loss: 0.3923 - recall: 0.7882 - val_loss: 0.6480 - val_recall: 0.2114\n",
      "Epoch 9/10\n",
      "5482/5482 [==============================] - 27s 5ms/step - loss: 0.3604 - recall: 0.8104 - val_loss: 0.5751 - val_recall: 0.0943\n",
      "Epoch 10/10\n",
      "5482/5482 [==============================] - 27s 5ms/step - loss: 0.3426 - recall: 0.8140 - val_loss: 0.5965 - val_recall: 0.2114\n",
      "Train on 5490 samples, validate on 346 samples\n",
      "Epoch 1/10\n",
      "5490/5490 [==============================] - 32s 6ms/step - loss: 1.4703 - recall: 0.5357 - val_loss: 1.3200 - val_recall: 0.8472\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_recall,loss,recall\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5490/5490 [==============================] - 27s 5ms/step - loss: 1.0831 - recall: 0.6079 - val_loss: 1.0257 - val_recall: 0.7438\n",
      "Epoch 3/10\n",
      "5490/5490 [==============================] - 27s 5ms/step - loss: 0.8485 - recall: 0.5745 - val_loss: 0.8472 - val_recall: 0.5679\n",
      "Epoch 4/10\n",
      "5490/5490 [==============================] - 26s 5ms/step - loss: 0.6705 - recall: 0.6294 - val_loss: 0.7810 - val_recall: 0.4541\n",
      "Epoch 5/10\n",
      "5490/5490 [==============================] - 27s 5ms/step - loss: 0.5852 - recall: 0.6543 - val_loss: 0.6946 - val_recall: 0.1952\n",
      "Epoch 6/10\n",
      "5490/5490 [==============================] - 27s 5ms/step - loss: 0.5140 - recall: 0.7083 - val_loss: 0.6217 - val_recall: 0.1085\n",
      "Epoch 7/10\n",
      "5490/5490 [==============================] - 27s 5ms/step - loss: 0.4718 - recall: 0.7243 - val_loss: 0.5652 - val_recall: 0.0887\n",
      "Epoch 8/10\n",
      "5490/5490 [==============================] - 27s 5ms/step - loss: 0.5251 - recall: 0.7708 - val_loss: 1.7835 - val_recall: 0.8684\n",
      "Epoch 9/10\n",
      "5490/5490 [==============================] - 27s 5ms/step - loss: 0.7821 - recall: 0.6427 - val_loss: 0.7419 - val_recall: 0.8260\n",
      "Epoch 10/10\n",
      "5490/5490 [==============================] - 26s 5ms/step - loss: 0.7226 - recall: 0.6182 - val_loss: 0.7773 - val_recall: 0.8273\n",
      "CNN-LSTM Accuracy Score ->  [0.08453410365739542, 0.19490417073714286, 0.3239467497861351, 0.11681076154241644, 0.1649325638148137, 0.19818332291751928, 0.16377649400275568, 0.04190751445086705, 0.19730250683823072, 0.8659785221077804]\n"
     ]
    }
   ],
   "source": [
    "cvscorescnnlstm = [] \n",
    "for train, test in cv.split(token):\n",
    "    #print(\"TRAIN:\", train, \"Test:\", test) \n",
    "    Xtrain, Xtest = token[train], token[test]\n",
    "    Ytrain, Ytest = y[train], y[test]\n",
    "    #smote \n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    sm = SMOTE(random_state=2) \n",
    "    X_train_res, y_train_res = sm.fit_sample(Xtrain, Ytrain)\n",
    "    seed = 126\n",
    "    np.random.seed(seed)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, weights = [embedding_matrix], trainable=False, input_length = X_train_res.shape[1]))\n",
    "    model.add(Conv1D(134, 5, activation='tanh'))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Conv1D(114, 5, activation='tanh'))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Dense(20, activation='tanh', kernel_regularizer = regularizers.l2(0.02)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(94,return_sequences=True, activation='tanh'))#return_sequences=True\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10,activation = 'tanh', kernel_regularizer = regularizers.l2(0.02)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[recall])\n",
    "    batch_size = 110\n",
    "    epochs = 10\n",
    "    \n",
    "    model_history = model.fit(X_train_res, y_train_res, validation_data=(Xtest, Ytest), epochs=epochs, batch_size=batch_size, verbose=1 ,callbacks=[EarlyStopping(monitor='val_acc',patience=4, mode='max', min_delta = 0.001)])\n",
    "    CLSTM = model.predict_classes(Xtest)\n",
    "        \n",
    "    scores2 = model.evaluate(Xtest, Ytest, verbose=0)\n",
    "    cvscorescnnlstm.append(scores2[1])\n",
    "\n",
    "print(\"CNN-LSTM Accuracy Score -> \",cvscorescnnlstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=13.282, p=0.001\n",
      "reject H0\n"
     ]
    }
   ],
   "source": [
    "#Friedman ChiSquare Test \n",
    "\n",
    "from scipy.stats import friedmanchisquare\n",
    "stats, p_value = friedmanchisquare(scoreSVM, cvscorescnn, cvscorescnnlstm)\n",
    "print('Statistics=%.3f, p=%.3f'%(stats, p_value))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p_value > alpha:\n",
    "    print('fail to reject H0')\n",
    "else:\n",
    "    print('reject H0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
