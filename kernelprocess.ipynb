{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import nltk                                         #Natural language processing tool-kit\n",
    "from nltk.corpus import stopwords                   #Stopwords corpus\n",
    "\n",
    "import re\n",
    "\n",
    "# %% [code]\n",
    "\n",
    "def processing (train):\n",
    "    train['Comments']=train['Comments'].astype(str) #converting comments to string\n",
    "    #Stopwords\n",
    "    stop = set(stopwords.words('english')) \n",
    "    #Removing Stopwords\n",
    "    train['Comments'] = train['Comments'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    #Lowercase\n",
    "    train['Comments'] = train['Comments'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    #punctuations removing\n",
    "    train['Comments']= train['Comments'].str.replace('[!”#$%&’()*+,-./:;<=>?[\\]^_`{|}~]','')\n",
    "    #numbers removing\n",
    "    train['Comments']= train['Comments'].str.replace('[1234567890]','')\n",
    "    #finding top 5 most common words\n",
    "    Most_common_word = pd.Series(' '.join(train['Comments']).split()).value_counts()[:5]\n",
    "    #finding top 20 most rare words\n",
    "    rare_word = pd.Series(' '.join(train['Comments']).split()).value_counts()[-20:]\n",
    "    #Removing Common &rare words\n",
    "    train['Comments'] =train['Comments'].apply(lambda x: \" \".join(x for x in x.split() if x not in rare_word))\n",
    "    train['Comments'] =train['Comments'].apply(lambda x: \" \".join(x for x in x.split() if x not in Most_common_word))\n",
    "    #data cleaning\n",
    "    train['Comments'] = train['Comments'].apply(lambda x : re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\\1\", x))\n",
    "    train['Comments'] = train['Comments'].apply(lambda x : re.sub(r\"([a-z],2)\\1{2,}\", r\"\\1\\1\\1\", x))\n",
    "    train['Comments'] = train['Comments'].apply(lambda x : re.sub(r\"@\\w+\", r\"@username\", x))\n",
    "    \n",
    "    lemm=[]\n",
    "    # Lemmatize with POS Tag\n",
    "    from nltk.corpus import wordnet\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    def get_wordnet_pos(word):\n",
    "        \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "        tag = nltk.pos_tag([word])[0][1][0]\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "        \n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "        \n",
    "        \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for sentence in train['Comments']:\n",
    "        words = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)]\n",
    "        lemm.append(words)\n",
    "    train['Comments'] = lemm\n",
    "    final = []\n",
    "    for row in train['Comments']:\n",
    "        sequ = ''\n",
    "        for word in row:\n",
    "            sequ = sequ + ' ' + word\n",
    "        final.append(sequ)\n",
    "    train['Comments'] = final\n",
    "    #Stemming\n",
    "    stemm = []\n",
    "    nltsnow = nltk.stem.SnowballStemmer('english')\n",
    "    for sentence in train['Comments']:\n",
    "        words = [nltsnow.stem(word) for word in sentence.split()]   \n",
    "        stemm.append(words)\n",
    "    train['Comments'] = stemm\n",
    "    \n",
    "    finalprocessing = []\n",
    "    for row in train['Comments']:\n",
    "        sequ = ''\n",
    "        for word in row:\n",
    "            sequ = sequ + ' ' + word\n",
    "        finalprocessing.append(sequ)\n",
    "    train['Comments'] = finalprocessing\n",
    "    \n",
    "    train = train.drop([\"UserIndex\", \"Number of Comments\", \"Number of Subscribers\", \"Membership Duration\", \"Number of Uploads\", \"Profanity in UserID\", \"Age\"], axis = 1)\n",
    "    return (train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
